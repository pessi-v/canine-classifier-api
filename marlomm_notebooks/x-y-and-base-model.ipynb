{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":308849,"sourceType":"datasetVersion","datasetId":129000}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tensorflow.keras.utils import image_dataset_from_directory\n\nimages = image_dataset_from_directory(\"/kaggle/input/stanford-dogs-dataset-traintest/cropped/cropped/train\", seed=1234, subset=\"both\", validation_split=0.2, batch_size=32, labels=\"inferred\", label_mode = \"categorical\")\nimages[0]","metadata":{"execution":{"iopub.status.busy":"2024-02-05T16:21:45.206590Z","iopub.execute_input":"2024-02-05T16:21:45.207642Z","iopub.status.idle":"2024-02-05T16:21:48.146201Z","shell.execute_reply.started":"2024-02-05T16:21:45.207595Z","shell.execute_reply":"2024-02-05T16:21:48.145313Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Found 12000 files belonging to 120 classes.\nUsing 9600 files for training.\nUsing 2400 files for validation.\nFound 12000 files belonging to 120 classes.\nUsing 2400 files for validation.\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 120), dtype=tf.float32, name=None))>"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras.applications.vgg16 import VGG16\n\ndef load_model():\n\n    model = VGG16(include_top=False, weights='imagenet', input_shape=(256, 256, 3))\n\n    return model\n\ndef set_nontrainable_layers(model):\n\n    model.trainable = False\n\n    return model\n\nmodel = load_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-02-05T16:02:20.482815Z","iopub.execute_input":"2024-02-05T16:02:20.483624Z","iopub.status.idle":"2024-02-05T16:02:21.580747Z","shell.execute_reply.started":"2024-02-05T16:02:20.483585Z","shell.execute_reply":"2024-02-05T16:02:21.579651Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n58889256/58889256 [==============================] - 0s 0us/step\nModel: \"vgg16\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 256, 256, 3)]     0         \n                                                                 \n block1_conv1 (Conv2D)       (None, 256, 256, 64)      1792      \n                                                                 \n block1_conv2 (Conv2D)       (None, 256, 256, 64)      36928     \n                                                                 \n block1_pool (MaxPooling2D)  (None, 128, 128, 64)      0         \n                                                                 \n block2_conv1 (Conv2D)       (None, 128, 128, 128)     73856     \n                                                                 \n block2_conv2 (Conv2D)       (None, 128, 128, 128)     147584    \n                                                                 \n block2_pool (MaxPooling2D)  (None, 64, 64, 128)       0         \n                                                                 \n block3_conv1 (Conv2D)       (None, 64, 64, 256)       295168    \n                                                                 \n block3_conv2 (Conv2D)       (None, 64, 64, 256)       590080    \n                                                                 \n block3_conv3 (Conv2D)       (None, 64, 64, 256)       590080    \n                                                                 \n block3_pool (MaxPooling2D)  (None, 32, 32, 256)       0         \n                                                                 \n block4_conv1 (Conv2D)       (None, 32, 32, 512)       1180160   \n                                                                 \n block4_conv2 (Conv2D)       (None, 32, 32, 512)       2359808   \n                                                                 \n block4_conv3 (Conv2D)       (None, 32, 32, 512)       2359808   \n                                                                 \n block4_pool (MaxPooling2D)  (None, 16, 16, 512)       0         \n                                                                 \n block5_conv1 (Conv2D)       (None, 16, 16, 512)       2359808   \n                                                                 \n block5_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n                                                                 \n block5_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n                                                                 \n block5_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n                                                                 \n=================================================================\nTotal params: 14714688 (56.13 MB)\nTrainable params: 14714688 (56.13 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras import layers, models\nimport tensorflow as tf\n\ndef add_last_layers(model):\n    '''Take a pre-trained model, set its parameters as non-trainable, and add additional trainable layers on top'''\n    flattening_layer = layers.Flatten()\n    dense_layer = layers.Dense(500, activation='relu')\n    prediction_layer = layers.Dense(120, activation='softmax')\n    model = tf.keras.Sequential([\n      model,\n      flattening_layer,\n      dense_layer,\n      prediction_layer\n    ])\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-02-05T16:02:31.240754Z","iopub.execute_input":"2024-02-05T16:02:31.241148Z","iopub.status.idle":"2024-02-05T16:02:31.249717Z","shell.execute_reply.started":"2024-02-05T16:02:31.241120Z","shell.execute_reply":"2024-02-05T16:02:31.248907Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import optimizers\n\ndef build_model():\n    base_model = load_model()\n    base_model = set_nontrainable_layers(base_model)\n    model = add_last_layers(base_model)\n    model.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.Adam(learning_rate=1e-4),\n              metrics=['accuracy'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-02-05T16:02:32.967355Z","iopub.execute_input":"2024-02-05T16:02:32.967716Z","iopub.status.idle":"2024-02-05T16:02:32.973089Z","shell.execute_reply.started":"2024-02-05T16:02:32.967687Z","shell.execute_reply":"2024-02-05T16:02:32.972122Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications.vgg16 import preprocess_input\nfrom tensorflow.keras.callbacks import EarlyStopping\n\naug_images = images[0].map(\n  lambda x, y: (preprocess_input(x), y))\naug_images_val = images[1].map(\n  lambda x, y: (preprocess_input(x), y))\n\nmodel = build_model()\nmodel.summary()\nes = EarlyStopping(patience=3)\nhistory = model.fit(aug_images,\n          epochs=100,\n          batch_size=32,\n          callbacks=es,\n          validation_data=aug_images_val,\n          verbose=1)","metadata":{"execution":{"iopub.status.busy":"2024-02-05T16:28:59.674561Z","iopub.execute_input":"2024-02-05T16:28:59.675498Z","iopub.status.idle":"2024-02-05T16:35:53.739729Z","shell.execute_reply.started":"2024-02-05T16:28:59.675450Z","shell.execute_reply":"2024-02-05T16:35:53.738717Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Model: \"sequential_4\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n vgg16 (Functional)          (None, 8, 8, 512)         14714688  \n                                                                 \n flatten_4 (Flatten)         (None, 32768)             0         \n                                                                 \n dense_8 (Dense)             (None, 500)               16384500  \n                                                                 \n dense_9 (Dense)             (None, 120)               60120     \n                                                                 \n=================================================================\nTotal params: 31159308 (118.86 MB)\nTrainable params: 16444620 (62.73 MB)\nNon-trainable params: 14714688 (56.13 MB)\n_________________________________________________________________\nEpoch 1/100\n300/300 [==============================] - 70s 228ms/step - loss: 6.3054 - accuracy: 0.1003 - val_loss: 3.8339 - val_accuracy: 0.1858\nEpoch 2/100\n300/300 [==============================] - 68s 226ms/step - loss: 1.8221 - accuracy: 0.5482 - val_loss: 3.2204 - val_accuracy: 0.3438\nEpoch 3/100\n300/300 [==============================] - 69s 228ms/step - loss: 0.4001 - accuracy: 0.8868 - val_loss: 3.2166 - val_accuracy: 0.4042\nEpoch 4/100\n300/300 [==============================] - 69s 228ms/step - loss: 0.1009 - accuracy: 0.9785 - val_loss: 3.2670 - val_accuracy: 0.4367\nEpoch 5/100\n300/300 [==============================] - 69s 228ms/step - loss: 0.0474 - accuracy: 0.9927 - val_loss: 3.3515 - val_accuracy: 0.4358\nEpoch 6/100\n300/300 [==============================] - 69s 228ms/step - loss: 0.0325 - accuracy: 0.9948 - val_loss: 3.3716 - val_accuracy: 0.4538\n","output_type":"stream"}]}]}