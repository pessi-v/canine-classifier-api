{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":308849,"sourceType":"datasetVersion","datasetId":129000}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-02-08T10:56:45.516904Z","iopub.execute_input":"2024-02-08T10:56:45.517498Z","iopub.status.idle":"2024-02-08T10:56:45.522862Z","shell.execute_reply.started":"2024-02-08T10:56:45.517461Z","shell.execute_reply":"2024-02-08T10:56:45.521644Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print('DEVICES AVAILABLE: {}'.format(strategy.num_replicas_in_sync))","metadata":{"execution":{"iopub.status.busy":"2024-02-08T11:05:36.264675Z","iopub.execute_input":"2024-02-08T11:05:36.265032Z","iopub.status.idle":"2024-02-08T11:05:36.270135Z","shell.execute_reply.started":"2024-02-08T11:05:36.265004Z","shell.execute_reply":"2024-02-08T11:05:36.269200Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"DEVICES AVAILABLE: 2\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Comparing V2L and V2S","metadata":{}},{"cell_type":"code","source":"import tensorflow.keras.applications as pmodels\nfrom tensorflow.keras import layers, models, optimizers\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.utils import image_dataset_from_directory\nimport tensorflow as tf\nstrategy = tf.distribute.MirroredStrategy()\n\ndef test_base_models():\n    images = image_dataset_from_directory(\"/kaggle/input/stanford-dogs-dataset-traintest/cropped/train\", \n                                      seed=1234, subset=\"both\", validation_split=0.2, batch_size=32, \n                                      labels=\"inferred\", label_mode = \"categorical\")\n    test_images = image_dataset_from_directory(\"/kaggle/input/stanford-dogs-dataset-traintest/cropped/test\", \n                                      seed=1234, batch_size=32, \n                                      labels=\"inferred\", label_mode = \"categorical\")\n    base_models = [pmodels.efficientnet_v2.EfficientNetV2L, pmodels.efficientnet_v2.EfficientNetV2S]\n    preprocess_func = [do_nothing, do_nothing]\n    histories = []\n    scores = []\n    models = []\n    for index, base_model in enumerate(base_models):\n        model = build_model(base_model)\n        images_train = images[0].map(lambda x, y: (preprocess_func[index](x), y))\n        images_val = images[1].map(lambda x, y: (preprocess_func[index](x), y))\n        images_test = test_images.map(lambda x, y: (preprocess_func[index](x), y))\n        history = train_model(model, images_train, images_val)\n        score = evaluate_model(model, images_test)\n        histories.append(history)\n        scores.append(score)\n        models.append(model)\n    return histories, scores, models, base_models\n\ndef add_last_layers(model):\n    '''Take a pre-trained model, set its parameters as non-trainable, and add additional trainable layers on top'''\n    flattening_layer = layers.Flatten()\n    dense_layer = layers.Dense(500, activation='relu')\n    prediction_layer = layers.Dense(120, activation='softmax')\n\n    model = models.Sequential([\n      model,\n      flattening_layer,\n      dense_layer,\n      prediction_layer\n    ])\n\n    return model\n\ndef build_model(base_model):\n    with strategy.scope():\n        model = load_model(base_model)\n        model = set_nontrainable_layers(model)\n        model = add_last_layers(model)\n        model.compile(loss='categorical_crossentropy',\n                  optimizer=optimizers.Adam(),\n                  metrics=['accuracy'])\n        return model\n\ndef load_model(base_model):\n    model = base_model(include_top=False, weights='imagenet', input_shape=(256, 256, 3))\n    return model\n\ndef set_nontrainable_layers(model):\n    model.trainable = False\n    return model\n\ndef train_model(model, images_train, images_val):\n    model.summary()\n    es = EarlyStopping(monitor=\"val_accuracy\", patience=3, restore_best_weights=True)\n    history = model.fit(images_train,\n              epochs=100,\n              batch_size=32,\n              callbacks=es,\n              validation_data=images_val,\n              verbose=1)\n    return history\n\ndef evaluate_model(model, images_test):\n    return model.evaluate(images_test)\n\ndef do_nothing(object):\n    return object\n\nhistories, scores, models, base_models = test_base_models()","metadata":{"execution":{"iopub.status.busy":"2024-02-08T11:12:44.711475Z","iopub.execute_input":"2024-02-08T11:12:44.712056Z","iopub.status.idle":"2024-02-08T11:35:09.358007Z","shell.execute_reply.started":"2024-02-08T11:12:44.712010Z","shell.execute_reply":"2024-02-08T11:35:09.357240Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-02-08 11:12:48.317280: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-08 11:12:48.317374: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-08 11:12:48.625325: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Found 12000 files belonging to 120 classes.\nUsing 9600 files for training.\nUsing 2400 files for validation.\nFound 8580 files belonging to 120 classes.\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-l_notop.h5\n473176280/473176280 [==============================] - 4s 0us/step\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n efficientnetv2-l (Function  (None, 8, 8, 1280)        117746848 \n al)                                                             \n                                                                 \n flatten (Flatten)           (None, 81920)             0         \n                                                                 \n dense (Dense)               (None, 500)               40960500  \n                                                                 \n dense_1 (Dense)             (None, 120)               60120     \n                                                                 \n=================================================================\nTotal params: 158767468 (605.65 MB)\nTrainable params: 41020620 (156.48 MB)\nNon-trainable params: 117746848 (449.17 MB)\n_________________________________________________________________\nEpoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"2024-02-08 11:14:36.790426: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/efficientnetv2-l/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1707390886.446468     103 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"300/300 [==============================] - 203s 450ms/step - loss: 2.2275 - accuracy: 0.7496 - val_loss: 0.5395 - val_accuracy: 0.8763\nEpoch 2/100\n300/300 [==============================] - 118s 394ms/step - loss: 0.5879 - accuracy: 0.8930 - val_loss: 0.6440 - val_accuracy: 0.8637\nEpoch 3/100\n300/300 [==============================] - 119s 396ms/step - loss: 0.3857 - accuracy: 0.9170 - val_loss: 0.6705 - val_accuracy: 0.8842\nEpoch 4/100\n300/300 [==============================] - 119s 397ms/step - loss: 0.3372 - accuracy: 0.9248 - val_loss: 0.7198 - val_accuracy: 0.8792\nEpoch 5/100\n300/300 [==============================] - 118s 393ms/step - loss: 0.3317 - accuracy: 0.9274 - val_loss: 0.8728 - val_accuracy: 0.8717\nEpoch 6/100\n300/300 [==============================] - 121s 404ms/step - loss: 0.3166 - accuracy: 0.9343 - val_loss: 0.8359 - val_accuracy: 0.8808\n269/269 [==============================] - 72s 266ms/step - loss: 0.6034 - accuracy: 0.8900\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-s_notop.h5\n82420632/82420632 [==============================] - 0s 0us/step\nModel: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n efficientnetv2-s (Function  (None, 8, 8, 1280)        20331360  \n al)                                                             \n                                                                 \n flatten_1 (Flatten)         (None, 81920)             0         \n                                                                 \n dense_2 (Dense)             (None, 500)               40960500  \n                                                                 \n dense_3 (Dense)             (None, 120)               60120     \n                                                                 \n=================================================================\nTotal params: 61351980 (234.04 MB)\nTrainable params: 41020620 (156.48 MB)\nNon-trainable params: 20331360 (77.56 MB)\n_________________________________________________________________\nEpoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"2024-02-08 11:28:52.177324: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_1/efficientnetv2-s/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"300/300 [==============================] - 97s 220ms/step - loss: 1.6200 - accuracy: 0.7352 - val_loss: 0.8083 - val_accuracy: 0.8408\nEpoch 2/100\n300/300 [==============================] - 56s 185ms/step - loss: 0.4382 - accuracy: 0.9041 - val_loss: 0.9845 - val_accuracy: 0.8438\nEpoch 3/100\n300/300 [==============================] - 56s 187ms/step - loss: 0.4621 - accuracy: 0.9209 - val_loss: 0.8150 - val_accuracy: 0.8717\nEpoch 4/100\n300/300 [==============================] - 55s 182ms/step - loss: 0.3464 - accuracy: 0.9353 - val_loss: 1.0838 - val_accuracy: 0.8558\nEpoch 5/100\n300/300 [==============================] - 55s 183ms/step - loss: 0.2851 - accuracy: 0.9461 - val_loss: 1.0363 - val_accuracy: 0.8637\nEpoch 6/100\n300/300 [==============================] - 56s 186ms/step - loss: 0.2342 - accuracy: 0.9566 - val_loss: 1.1149 - val_accuracy: 0.8658\n269/269 [==============================] - 30s 108ms/step - loss: 0.7186 - accuracy: 0.8871\n","output_type":"stream"}]},{"cell_type":"markdown","source":".89 vs. .8871 performance on the test set makes not much of a difference, but runtime is halfed --> using V2S for now.","metadata":{}},{"cell_type":"markdown","source":"# Trying out data augmentation","metadata":{}},{"cell_type":"code","source":"import tensorflow.keras.applications as pmodels\nfrom tensorflow.keras import layers, models, optimizers\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.utils import image_dataset_from_directory\nimport tensorflow as tf\nstrategy = tf.distribute.MirroredStrategy()\n\ndef test_base_models():\n    images = image_dataset_from_directory(\"/kaggle/input/stanford-dogs-dataset-traintest/cropped/train\", \n                                      seed=1234, subset=\"both\", validation_split=0.2, batch_size=32, \n                                      labels=\"inferred\", label_mode = \"categorical\")\n    test_images = image_dataset_from_directory(\"/kaggle/input/stanford-dogs-dataset-traintest/cropped/test\", \n                                      seed=1234, batch_size=32, \n                                      labels=\"inferred\", label_mode = \"categorical\")\n    base_models = [pmodels.efficientnet_v2.EfficientNetV2S]\n    preprocess_func = [do_nothing]\n    histories = []\n    scores = []\n    models = []\n    for index, base_model in enumerate(base_models):\n        model = build_model(base_model)\n        images_train = images[0].map(lambda x, y: (preprocess_func[index](x), y))\n        data_augmentation = tf.keras.Sequential([layers.RandomFlip(\"horizontal\")])\n        images_train = images_train.map(lambda x, y: (data_augmentation(x, training=True), y))\n        images_val = images[1].map(lambda x, y: (preprocess_func[index](x), y))\n        images_test = test_images.map(lambda x, y: (preprocess_func[index](x), y))\n        history = train_model(model, images_train, images_val)\n        score = evaluate_model(model, images_test)\n        histories.append(history)\n        scores.append(score)\n        models.append(model)\n    return histories, scores, models, base_models\n\ndef add_last_layers(model):\n    '''Take a pre-trained model, set its parameters as non-trainable, and add additional trainable layers on top'''\n    flattening_layer = layers.Flatten()\n    dense_layer = layers.Dense(500, activation='relu')\n    prediction_layer = layers.Dense(120, activation='softmax')\n\n    model = models.Sequential([\n      model,\n      flattening_layer,\n      dense_layer,\n      prediction_layer\n    ])\n\n    return model\n\ndef build_model(base_model):\n    with strategy.scope():\n        model = load_model(base_model)\n        model = set_nontrainable_layers(model)\n        model = add_last_layers(model)\n        model.compile(loss='categorical_crossentropy',\n                  optimizer=optimizers.Adam(),\n                  metrics=['accuracy'])\n        return model\n\ndef load_model(base_model):\n    model = base_model(include_top=False, weights='imagenet', input_shape=(256, 256, 3))\n    return model\n\ndef set_nontrainable_layers(model):\n    model.trainable = False\n    return model\n\ndef train_model(model, images_train, images_val):\n    model.summary()\n    es = EarlyStopping(monitor=\"val_accuracy\", patience=3, restore_best_weights=True)\n    history = model.fit(images_train,\n              epochs=100,\n              batch_size=32,\n              callbacks=es,\n              validation_data=images_val,\n              verbose=1)\n    return history\n\ndef evaluate_model(model, images_test):\n    return model.evaluate(images_test)\n\ndef do_nothing(object):\n    return object\n\nhistories, scores, models, base_models = test_base_models()","metadata":{"execution":{"iopub.status.busy":"2024-02-08T11:59:18.594564Z","iopub.execute_input":"2024-02-08T11:59:18.595282Z","iopub.status.idle":"2024-02-08T12:05:21.705841Z","shell.execute_reply.started":"2024-02-08T11:59:18.595239Z","shell.execute_reply":"2024-02-08T12:05:21.705057Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Found 12000 files belonging to 120 classes.\nUsing 9600 files for training.\nUsing 2400 files for validation.\nFound 8580 files belonging to 120 classes.\nModel: \"sequential_6\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n efficientnetv2-s (Function  (None, 8, 8, 1280)        20331360  \n al)                                                             \n                                                                 \n flatten_4 (Flatten)         (None, 81920)             0         \n                                                                 \n dense_8 (Dense)             (None, 500)               40960500  \n                                                                 \n dense_9 (Dense)             (None, 120)               60120     \n                                                                 \n=================================================================\nTotal params: 61351980 (234.04 MB)\nTrainable params: 41020620 (156.48 MB)\nNon-trainable params: 20331360 (77.56 MB)\n_________________________________________________________________\nEpoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"2024-02-08 12:00:06.684793: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_6/efficientnetv2-s/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"300/300 [==============================] - 95s 209ms/step - loss: 1.5298 - accuracy: 0.7371 - val_loss: 0.6731 - val_accuracy: 0.8517\nEpoch 2/100\n300/300 [==============================] - 56s 186ms/step - loss: 0.5707 - accuracy: 0.8734 - val_loss: 0.7294 - val_accuracy: 0.8725\nEpoch 3/100\n300/300 [==============================] - 55s 183ms/step - loss: 0.4725 - accuracy: 0.9033 - val_loss: 0.8077 - val_accuracy: 0.8604\nEpoch 4/100\n300/300 [==============================] - 55s 184ms/step - loss: 0.4958 - accuracy: 0.9065 - val_loss: 0.9524 - val_accuracy: 0.8583\nEpoch 5/100\n300/300 [==============================] - 57s 190ms/step - loss: 0.3700 - accuracy: 0.9239 - val_loss: 0.8949 - val_accuracy: 0.8721\n269/269 [==============================] - 25s 91ms/step - loss: 0.6784 - accuracy: 0.8724\n","output_type":"stream"}]},{"cell_type":"markdown","source":"* 0.884 with horizontal flipping and random rotation\n* 0.8724 with just horizontal flipping","metadata":{}},{"cell_type":"markdown","source":"# Changing batch size","metadata":{}},{"cell_type":"code","source":"import tensorflow.keras.applications as pmodels\nfrom tensorflow.keras import layers, models, optimizers\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.utils import image_dataset_from_directory\nimport tensorflow as tf\nstrategy = tf.distribute.MirroredStrategy()\n\ndef test_base_models():\n    images = image_dataset_from_directory(\"/kaggle/input/stanford-dogs-dataset-traintest/cropped/train\", \n                                      seed=1234, subset=\"both\", validation_split=0.2, batch_size=64, \n                                      labels=\"inferred\", label_mode = \"categorical\")\n    test_images = image_dataset_from_directory(\"/kaggle/input/stanford-dogs-dataset-traintest/cropped/test\", \n                                      seed=1234, batch_size=32, \n                                      labels=\"inferred\", label_mode = \"categorical\")\n    base_models = [pmodels.efficientnet_v2.EfficientNetV2S]\n    preprocess_func = [do_nothing]\n    histories = []\n    scores = []\n    models = []\n    for index, base_model in enumerate(base_models):\n        model = build_model(base_model)\n        images_train = images[0].map(lambda x, y: (preprocess_func[index](x), y))\n        images_val = images[1].map(lambda x, y: (preprocess_func[index](x), y))\n        images_test = test_images.map(lambda x, y: (preprocess_func[index](x), y))\n        history = train_model(model, images_train, images_val)\n        score = evaluate_model(model, images_test)\n        histories.append(history)\n        scores.append(score)\n        models.append(model)\n    return histories, scores, models, base_models\n\ndef add_last_layers(model):\n    '''Take a pre-trained model, set its parameters as non-trainable, and add additional trainable layers on top'''\n    flattening_layer = layers.Flatten()\n    dense_layer = layers.Dense(500, activation='relu')\n    prediction_layer = layers.Dense(120, activation='softmax')\n\n    model = models.Sequential([\n      model,\n      flattening_layer,\n      dense_layer,\n      prediction_layer\n    ])\n\n    return model\n\ndef build_model(base_model):\n    with strategy.scope():\n        model = load_model(base_model)\n        model = set_nontrainable_layers(model)\n        model = add_last_layers(model)\n        model.compile(loss='categorical_crossentropy',\n                  optimizer=optimizers.Adam(),\n                  metrics=['accuracy'])\n        return model\n\ndef load_model(base_model):\n    model = base_model(include_top=False, weights='imagenet', input_shape=(256, 256, 3))\n    return model\n\ndef set_nontrainable_layers(model):\n    model.trainable = False\n    return model\n\ndef train_model(model, images_train, images_val):\n    model.summary()\n    es = EarlyStopping(monitor=\"val_accuracy\", patience=3, restore_best_weights=True)\n    history = model.fit(images_train,\n              epochs=100,\n              batch_size=64,\n              callbacks=es,\n              validation_data=images_val,\n              verbose=1)\n    return history\n\ndef evaluate_model(model, images_test):\n    return model.evaluate(images_test)\n\ndef do_nothing(object):\n    return object\n\nhistories, scores, models, base_models = test_base_models()","metadata":{"execution":{"iopub.status.busy":"2024-02-08T12:10:50.839023Z","iopub.execute_input":"2024-02-08T12:10:50.839656Z","iopub.status.idle":"2024-02-08T12:18:28.130585Z","shell.execute_reply.started":"2024-02-08T12:10:50.839624Z","shell.execute_reply":"2024-02-08T12:18:28.129794Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Found 12000 files belonging to 120 classes.\nUsing 9600 files for training.\nUsing 2400 files for validation.\nFound 8580 files belonging to 120 classes.\nModel: \"sequential_9\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n efficientnetv2-s (Function  (None, 8, 8, 1280)        20331360  \n al)                                                             \n                                                                 \n flatten_6 (Flatten)         (None, 81920)             0         \n                                                                 \n dense_12 (Dense)            (None, 500)               40960500  \n                                                                 \n dense_13 (Dense)            (None, 120)               60120     \n                                                                 \n=================================================================\nTotal params: 61351980 (234.04 MB)\nTrainable params: 41020620 (156.48 MB)\nNon-trainable params: 20331360 (77.56 MB)\n_________________________________________________________________\nEpoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"2024-02-08 12:11:36.481063: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_9/efficientnetv2-s/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"150/150 [==============================] - 89s 387ms/step - loss: 1.4773 - accuracy: 0.7542 - val_loss: 0.6679 - val_accuracy: 0.8504\nEpoch 2/100\n150/150 [==============================] - 46s 302ms/step - loss: 0.3825 - accuracy: 0.9167 - val_loss: 0.7771 - val_accuracy: 0.8650\nEpoch 3/100\n150/150 [==============================] - 46s 304ms/step - loss: 0.2131 - accuracy: 0.9444 - val_loss: 0.7995 - val_accuracy: 0.8725\nEpoch 4/100\n150/150 [==============================] - 46s 304ms/step - loss: 0.2026 - accuracy: 0.9505 - val_loss: 0.8744 - val_accuracy: 0.8817\nEpoch 5/100\n150/150 [==============================] - 46s 306ms/step - loss: 0.1790 - accuracy: 0.9633 - val_loss: 0.8837 - val_accuracy: 0.8821\nEpoch 6/100\n150/150 [==============================] - 47s 312ms/step - loss: 0.1696 - accuracy: 0.9660 - val_loss: 1.0070 - val_accuracy: 0.8796\nEpoch 7/100\n150/150 [==============================] - 45s 301ms/step - loss: 0.1600 - accuracy: 0.9641 - val_loss: 1.0660 - val_accuracy: 0.8721\nEpoch 8/100\n150/150 [==============================] - 47s 307ms/step - loss: 0.2054 - accuracy: 0.9627 - val_loss: 1.1807 - val_accuracy: 0.8637\n269/269 [==============================] - 25s 92ms/step - loss: 0.7963 - accuracy: 0.8925\n","output_type":"stream"}]},{"cell_type":"markdown","source":"* worse for smaller batch size (16)\n* better for bigger batch size (64): 0.8925","metadata":{}},{"cell_type":"markdown","source":"# Changing the output layer","metadata":{}},{"cell_type":"markdown","source":"Global Average Pooling instead of Dense Layer","metadata":{}},{"cell_type":"code","source":"import tensorflow.keras.applications as pmodels\nfrom tensorflow.keras import layers, models, optimizers\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.utils import image_dataset_from_directory\nimport tensorflow as tf\nstrategy = tf.distribute.MirroredStrategy()\n\ndef test_base_models():\n    images = image_dataset_from_directory(\"/kaggle/input/stanford-dogs-dataset-traintest/cropped/train\", \n                                      seed=1234, subset=\"both\", validation_split=0.2, batch_size=64, \n                                      labels=\"inferred\", label_mode = \"categorical\")\n    test_images = image_dataset_from_directory(\"/kaggle/input/stanford-dogs-dataset-traintest/cropped/test\", \n                                      seed=1234, batch_size=32, \n                                      labels=\"inferred\", label_mode = \"categorical\")\n    base_models = [pmodels.efficientnet_v2.EfficientNetV2S]\n    preprocess_func = [do_nothing]\n    histories = []\n    scores = []\n    models = []\n    for index, base_model in enumerate(base_models):\n        model = build_model(base_model)\n        images_train = images[0].map(lambda x, y: (preprocess_func[index](x), y))\n        images_val = images[1].map(lambda x, y: (preprocess_func[index](x), y))\n        images_test = test_images.map(lambda x, y: (preprocess_func[index](x), y))\n        history = train_model(model, images_train, images_val)\n        score = evaluate_model(model, images_test)\n        histories.append(history)\n        scores.append(score)\n        models.append(model)\n    return histories, scores, models, base_models\n\ndef add_last_layers(model):\n    '''Take a pre-trained model, set its parameters as non-trainable, and add additional trainable layers on top'''\n    gap_layer = layers.GlobalAveragePooling2D()\n    prediction_layer = layers.Dense(120, activation='softmax')\n\n    model = models.Sequential([\n      model,\n      gap_layer,\n      prediction_layer\n    ])\n\n    return model\n\ndef build_model(base_model):\n\n    model = load_model(base_model)\n    model = set_nontrainable_layers(model)\n    model = add_last_layers(model)\n    model.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.Adam(),\n              metrics=['accuracy'])\n    return model\n\ndef load_model(base_model):\n    model = base_model(include_top=False, weights='imagenet', input_shape=(256, 256, 3))\n    return model\n\ndef set_nontrainable_layers(model):\n    model.trainable = False\n    return model\n\ndef train_model(model, images_train, images_val):\n    model.summary()\n    es = EarlyStopping(monitor=\"val_accuracy\", patience=3, restore_best_weights=True)\n    history = model.fit(images_train,\n              epochs=100,\n              batch_size=64,\n              callbacks=es,\n              validation_data=images_val,\n              verbose=1)\n    return history\n\ndef evaluate_model(model, images_test):\n    return model.evaluate(images_test)\n\ndef do_nothing(object):\n    return object\n\nhistories, scores, models, base_models = test_base_models()","metadata":{"execution":{"iopub.status.busy":"2024-02-08T12:38:55.312815Z","iopub.execute_input":"2024-02-08T12:38:55.313557Z","iopub.status.idle":"2024-02-08T12:44:56.619266Z","shell.execute_reply.started":"2024-02-08T12:38:55.313525Z","shell.execute_reply":"2024-02-08T12:44:56.618444Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Found 12000 files belonging to 120 classes.\nUsing 9600 files for training.\nUsing 2400 files for validation.\nFound 8580 files belonging to 120 classes.\nModel: \"sequential_13\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n efficientnetv2-s (Function  (None, 8, 8, 1280)        20331360  \n al)                                                             \n                                                                 \n global_average_pooling2d_3  (None, 1280)              0         \n  (GlobalAveragePooling2D)                                       \n                                                                 \n dense_17 (Dense)            (None, 120)               153720    \n                                                                 \n=================================================================\nTotal params: 20485080 (78.14 MB)\nTrainable params: 153720 (600.47 KB)\nNon-trainable params: 20331360 (77.56 MB)\n_________________________________________________________________\nEpoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"2024-02-08 12:39:18.396919: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_13/efficientnetv2-s/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"150/150 [==============================] - 84s 448ms/step - loss: 1.4844 - accuracy: 0.8122 - val_loss: 0.3594 - val_accuracy: 0.9187\nEpoch 2/100\n150/150 [==============================] - 57s 378ms/step - loss: 0.3116 - accuracy: 0.9189 - val_loss: 0.2741 - val_accuracy: 0.9237\nEpoch 3/100\n150/150 [==============================] - 57s 377ms/step - loss: 0.2476 - accuracy: 0.9276 - val_loss: 0.2598 - val_accuracy: 0.9196\nEpoch 4/100\n150/150 [==============================] - 57s 376ms/step - loss: 0.2154 - accuracy: 0.9346 - val_loss: 0.2545 - val_accuracy: 0.9179\nEpoch 5/100\n150/150 [==============================] - 57s 379ms/step - loss: 0.1938 - accuracy: 0.9410 - val_loss: 0.2507 - val_accuracy: 0.9200\n269/269 [==============================] - 39s 145ms/step - loss: 0.2429 - accuracy: 0.9315\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# GAP2D with Normalization and Dropout","metadata":{}},{"cell_type":"code","source":"import tensorflow.keras.applications as pmodels\nfrom tensorflow.keras import layers, models, optimizers\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.utils import image_dataset_from_directory\nimport tensorflow as tf\nstrategy = tf.distribute.MirroredStrategy()\n\ndef test_base_models():\n    images = image_dataset_from_directory(\"/kaggle/input/stanford-dogs-dataset-traintest/cropped/train\", \n                                      seed=1234, subset=\"both\", validation_split=0.2, batch_size=64, \n                                      labels=\"inferred\", label_mode = \"categorical\")\n    test_images = image_dataset_from_directory(\"/kaggle/input/stanford-dogs-dataset-traintest/cropped/test\", \n                                      seed=1234, batch_size=32, \n                                      labels=\"inferred\", label_mode = \"categorical\")\n    base_models = [pmodels.efficientnet_v2.EfficientNetV2S]\n    preprocess_func = [do_nothing]\n    histories = []\n    scores = []\n    models = []\n    for index, base_model in enumerate(base_models):\n        model = build_model(base_model)\n        images_train = images[0].map(lambda x, y: (preprocess_func[index](x), y))\n        images_val = images[1].map(lambda x, y: (preprocess_func[index](x), y))\n        images_test = test_images.map(lambda x, y: (preprocess_func[index](x), y))\n        history = train_model(model, images_train, images_val)\n        score = evaluate_model(model, images_test)\n        histories.append(history)\n        scores.append(score)\n        models.append(model)\n    return histories, scores, models, base_models\n\ndef add_last_layers(model):\n    '''Take a pre-trained model, set its parameters as non-trainable, and add additional trainable layers on top'''\n    gap_layer = layers.GlobalAveragePooling2D()\n    norm_layer = layers.BatchNormalization()\n    dropout_layer = layers.Dropout(0.2)\n    prediction_layer = layers.Dense(120, activation='softmax')\n\n    model = models.Sequential([\n      model,\n      gap_layer,\n      prediction_layer\n    ])\n\n    return model\n\ndef build_model(base_model):\n\n    model = load_model(base_model)\n    model = set_nontrainable_layers(model)\n    model = add_last_layers(model)\n    model.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.Adam(),\n              metrics=['accuracy'])\n    return model\n\ndef load_model(base_model):\n    model = base_model(include_top=False, weights='imagenet', input_shape=(256, 256, 3))\n    return model\n\ndef set_nontrainable_layers(model):\n    model.trainable = False\n    return model\n\ndef train_model(model, images_train, images_val):\n    model.summary()\n    es = EarlyStopping(monitor=\"val_accuracy\", patience=3, restore_best_weights=True)\n    history = model.fit(images_train,\n              epochs=100,\n              batch_size=64,\n              callbacks=es,\n              validation_data=images_val,\n              verbose=1)\n    return history\n\ndef evaluate_model(model, images_test):\n    return model.evaluate(images_test)\n\ndef do_nothing(object):\n    return object\n\nhistories, scores, models, base_models = test_base_models()","metadata":{"execution":{"iopub.status.busy":"2024-02-08T12:45:15.587295Z","iopub.execute_input":"2024-02-08T12:45:15.587689Z","iopub.status.idle":"2024-02-08T12:52:04.040508Z","shell.execute_reply.started":"2024-02-08T12:45:15.587657Z","shell.execute_reply":"2024-02-08T12:52:04.039684Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Found 12000 files belonging to 120 classes.\nUsing 9600 files for training.\nUsing 2400 files for validation.\nFound 8580 files belonging to 120 classes.\nModel: \"sequential_14\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n efficientnetv2-s (Function  (None, 8, 8, 1280)        20331360  \n al)                                                             \n                                                                 \n global_average_pooling2d_4  (None, 1280)              0         \n  (GlobalAveragePooling2D)                                       \n                                                                 \n dense_18 (Dense)            (None, 120)               153720    \n                                                                 \n=================================================================\nTotal params: 20485080 (78.14 MB)\nTrainable params: 153720 (600.47 KB)\nNon-trainable params: 20331360 (77.56 MB)\n_________________________________________________________________\nEpoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"2024-02-08 12:45:39.735562: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_14/efficientnetv2-s/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"150/150 [==============================] - 74s 402ms/step - loss: 1.4788 - accuracy: 0.8095 - val_loss: 0.3572 - val_accuracy: 0.9137\nEpoch 2/100\n150/150 [==============================] - 57s 377ms/step - loss: 0.3101 - accuracy: 0.9209 - val_loss: 0.2694 - val_accuracy: 0.9225\nEpoch 3/100\n150/150 [==============================] - 57s 376ms/step - loss: 0.2479 - accuracy: 0.9265 - val_loss: 0.2560 - val_accuracy: 0.9233\nEpoch 4/100\n150/150 [==============================] - 57s 377ms/step - loss: 0.2189 - accuracy: 0.9340 - val_loss: 0.2497 - val_accuracy: 0.9204\nEpoch 5/100\n150/150 [==============================] - 57s 377ms/step - loss: 0.1988 - accuracy: 0.9377 - val_loss: 0.2474 - val_accuracy: 0.9200\nEpoch 6/100\n150/150 [==============================] - 57s 379ms/step - loss: 0.1760 - accuracy: 0.9446 - val_loss: 0.2467 - val_accuracy: 0.9229\n269/269 [==============================] - 38s 140ms/step - loss: 0.2246 - accuracy: 0.9297\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Adding Dense layers after global pooling","metadata":{}},{"cell_type":"code","source":"import tensorflow.keras.applications as pmodels\nfrom tensorflow.keras import layers, models, optimizers\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.utils import image_dataset_from_directory\nimport tensorflow as tf\nstrategy = tf.distribute.MirroredStrategy()\n\ndef test_base_models():\n    images = image_dataset_from_directory(\"/kaggle/input/stanford-dogs-dataset-traintest/cropped/train\", \n                                      seed=1234, subset=\"both\", validation_split=0.2, batch_size=64, \n                                      labels=\"inferred\", label_mode = \"categorical\")\n    test_images = image_dataset_from_directory(\"/kaggle/input/stanford-dogs-dataset-traintest/cropped/test\", \n                                      seed=1234, batch_size=32, \n                                      labels=\"inferred\", label_mode = \"categorical\")\n    base_models = [pmodels.efficientnet_v2.EfficientNetV2S]\n    preprocess_func = [do_nothing]\n    histories = []\n    scores = []\n    models = []\n    for index, base_model in enumerate(base_models):\n        model = build_model(base_model)\n        images_train = images[0].map(lambda x, y: (preprocess_func[index](x), y))\n        images_val = images[1].map(lambda x, y: (preprocess_func[index](x), y))\n        images_test = test_images.map(lambda x, y: (preprocess_func[index](x), y))\n        history = train_model(model, images_train, images_val)\n        score = evaluate_model(model, images_test)\n        histories.append(history)\n        scores.append(score)\n        models.append(model)\n    return histories, scores, models, base_models\n\ndef add_last_layers(model):\n    '''Take a pre-trained model, set its parameters as non-trainable, and add additional trainable layers on top'''\n    gap_layer = layers.GlobalAveragePooling2D()\n    dense_layer = layers.Dense(500, activation='relu')\n    prediction_layer = layers.Dense(120, activation='softmax')\n\n    model = models.Sequential([\n      model,\n      gap_layer,\n      dense_layer,\n      prediction_layer\n    ])\n\n    return model\n\ndef build_model(base_model):\n\n    model = load_model(base_model)\n    model = set_nontrainable_layers(model)\n    model = add_last_layers(model)\n    model.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.Adam(),\n              metrics=['accuracy'])\n    return model\n\ndef load_model(base_model):\n    model = base_model(include_top=False, weights='imagenet', input_shape=(256, 256, 3))\n    return model\n\ndef set_nontrainable_layers(model):\n    model.trainable = False\n    return model\n\ndef train_model(model, images_train, images_val):\n    model.summary()\n    es = EarlyStopping(monitor=\"val_accuracy\", patience=3, restore_best_weights=True)\n    history = model.fit(images_train,\n              epochs=100,\n              batch_size=64,\n              callbacks=es,\n              validation_data=images_val,\n              verbose=1)\n    return history\n\ndef evaluate_model(model, images_test):\n    return model.evaluate(images_test)\n\ndef do_nothing(object):\n    return object\n\nhistories, scores, models, base_models = test_base_models()","metadata":{"execution":{"iopub.status.busy":"2024-02-08T13:00:41.423034Z","iopub.execute_input":"2024-02-08T13:00:41.423328Z","iopub.status.idle":"2024-02-08T13:09:06.091818Z","shell.execute_reply.started":"2024-02-08T13:00:41.423302Z","shell.execute_reply":"2024-02-08T13:09:06.090806Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-02-08 13:00:43.157846: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-08 13:00:43.157946: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-08 13:00:43.292753: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Found 12000 files belonging to 120 classes.\nUsing 9600 files for training.\nUsing 2400 files for validation.\nFound 8580 files belonging to 120 classes.\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-s_notop.h5\n82420632/82420632 [==============================] - 3s 0us/step\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n efficientnetv2-s (Function  (None, 8, 8, 1280)        20331360  \n al)                                                             \n                                                                 \n global_average_pooling2d (  (None, 1280)              0         \n GlobalAveragePooling2D)                                         \n                                                                 \n dense (Dense)               (None, 500)               640500    \n                                                                 \n dense_1 (Dense)             (None, 120)               60120     \n                                                                 \n=================================================================\nTotal params: 21031980 (80.23 MB)\nTrainable params: 700620 (2.67 MB)\nNon-trainable params: 20331360 (77.56 MB)\n_________________________________________________________________\nEpoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"2024-02-08 13:01:26.058254: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/efficientnetv2-s/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1707397292.653547      85 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"150/150 [==============================] - 84s 429ms/step - loss: 0.8492 - accuracy: 0.8314 - val_loss: 0.2887 - val_accuracy: 0.9112\nEpoch 2/100\n150/150 [==============================] - 58s 386ms/step - loss: 0.2594 - accuracy: 0.9190 - val_loss: 0.3038 - val_accuracy: 0.9021\nEpoch 3/100\n150/150 [==============================] - 58s 385ms/step - loss: 0.2081 - accuracy: 0.9299 - val_loss: 0.2957 - val_accuracy: 0.9100\nEpoch 4/100\n150/150 [==============================] - 58s 385ms/step - loss: 0.1804 - accuracy: 0.9397 - val_loss: 0.2969 - val_accuracy: 0.9146\nEpoch 5/100\n150/150 [==============================] - 58s 385ms/step - loss: 0.1562 - accuracy: 0.9461 - val_loss: 0.3060 - val_accuracy: 0.9062\nEpoch 6/100\n150/150 [==============================] - 58s 384ms/step - loss: 0.1293 - accuracy: 0.9559 - val_loss: 0.3164 - val_accuracy: 0.9087\nEpoch 7/100\n150/150 [==============================] - 58s 386ms/step - loss: 0.1266 - accuracy: 0.9521 - val_loss: 0.3170 - val_accuracy: 0.9104\n269/269 [==============================] - 40s 149ms/step - loss: 0.2612 - accuracy: 0.9245\n","output_type":"stream"}]}]}